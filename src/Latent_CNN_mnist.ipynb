{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNTQ-Zxpa-HB",
        "outputId": "a6c9fc55-541d-40c3-c444-9d0f853f60e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Feb 12 00:14:04 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPgPw0rnRuM4",
        "outputId": "9f1e1604-a361-4f95-8407-1ad8095a1d9a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "PATIENCE = 3"
      ],
      "metadata": {
        "id": "rIcQ_RqlzwDP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiMe3Tt4TVjf",
        "outputId": "ab6c79e0-5ec6-4bc1-c61c-81ce9ea2a7e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist_dataset():\n",
        "    mnist_dataset = load_dataset(\"mnist\")\n",
        "    transform = transforms.ToTensor()\n",
        "\n",
        "    def _transform_example(example):\n",
        "        example[\"image\"] = transform(example[\"image\"])\n",
        "        return example\n",
        "\n",
        "    mnist_dataset = mnist_dataset.map(_transform_example)\n",
        "    mnist_dataset.set_format(type=\"torch\", columns=[\"image\", \"label\"])\n",
        "\n",
        "    train_dataset = mnist_dataset[\"train\"]\n",
        "    test_dataset = mnist_dataset[\"test\"]\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "Vi4Ds0zBbleq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(64, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 28 * 28),\n",
        "            nn.Sigmoid()  # Normalise output to [0, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1) # [Batch, 1, 28, 28] → [Batch, 784]\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        decoded = decoded.view(x.size(0), 1, 28, 28) # [Batch, 784] → [Batch, 1, 28, 28]\n",
        "        return decoded\n",
        "\n",
        "    def get_latent(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        latent = self.encoder(x)\n",
        "        return latent"
      ],
      "metadata": {
        "id": "vMfL83mkbocp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1, dropout_prob: float = 0.2):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.downsample = None\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = ResidualBlock(16, 16, stride=1, dropout_prob=0.2)\n",
        "        self.layer2 = ResidualBlock(16, 32, stride=2, dropout_prob=0.2)\n",
        "        self.layer3 = ResidualBlock(32, 64, stride=2, dropout_prob=0.2)\n",
        "        self.layer4 = ResidualBlock(64, 64, stride=1, dropout_prob=0.2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout_fc = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout_fc(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "LTNlrTMofjBr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LatentCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LatentCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(p=0.5)  # Dropout-Wahrscheinlichkeit von 50%\n",
        "        self.fc = nn.Linear(32 * 8 * 8, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1, 8, 8)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jWLOsb2O0U6P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Evaluation functions\n",
        "# ---------------------------\n",
        "def evaluate_autoencoder(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            imgs = batch[\"image\"].to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, imgs)\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "    avg_loss = total_loss / len(data_loader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def evaluate_classifier(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            imgs = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    avg_loss = total_loss / len(data_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def evaluate_latentcnn(autoencoder, latentcnn, data_loader, criterion, device):\n",
        "    autoencoder.eval()\n",
        "    latentcnn.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            imgs = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            latent_imgs = autoencoder.get_latent(imgs)\n",
        "            outputs = latentcnn(latent_imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    avg_loss = total_loss / len(data_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "s0vezAdbWfhw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = load_mnist_dataset()\n",
        "\n",
        "autoencoder_model = Autoencoder().to(device)\n",
        "latentcnn_model = LatentCNN().to(device)\n",
        "residualcnn_model = ResidualCNN().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN0yQRxiOu0d",
        "outputId": "dda327c3-c1d2-453f-b8f7-3118ebfc30bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------\n",
        "# Training Autoencoder (Rekonstruktion, MSELoss)\n",
        "# ---------------------------------\n",
        "print(\"Training Autoencoder\")\n",
        "criterion_ae = nn.MSELoss()\n",
        "optimizer_ae = optim.Adam(autoencoder_model.parameters(), lr=1e-3)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    autoencoder_model.train()\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Autoencoder Epoch {epoch+1}/{NUM_EPOCHS}\", unit=\"batch\")\n",
        "    for batch in progress_bar:\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        outputs = autoencoder_model(imgs)\n",
        "        loss = criterion_ae(outputs, imgs)\n",
        "\n",
        "        optimizer_ae.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_ae.step()\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    val_loss = evaluate_autoencoder(autoencoder_model, test_loader, criterion_ae, device)\n",
        "    print(f\"Autoencoder Epoch {epoch+1} Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Early Stopping Logik\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_no_improve = 0\n",
        "        # Hier kann man den Modelldump speichern, z. B. torch.save(...)\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(\"Early stopping for Autoencoder\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CjV1flhb69b",
        "outputId": "f87c4e6f-91c2-4ae8-fa93-d6a091d7511c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Autoencoder\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Autoencoder Epoch 1/10: 100%|██████████| 938/938 [00:50<00:00, 18.71batch/s, loss=0.0307]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder Epoch 1 Validation Loss: 0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Autoencoder Epoch 2/10: 100%|██████████| 938/938 [00:37<00:00, 24.85batch/s, loss=0.0259]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder Epoch 2 Validation Loss: 0.0190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Autoencoder Epoch 3/10: 100%|██████████| 938/938 [00:35<00:00, 26.36batch/s, loss=0.0308]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder Epoch 3 Validation Loss: 0.0179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Autoencoder Epoch 4/10: 100%|██████████| 938/938 [00:35<00:00, 26.33batch/s, loss=0.0287]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder Epoch 4 Validation Loss: 0.0171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Autoencoder Epoch 5/10: 100%|██████████| 938/938 [00:36<00:00, 25.47batch/s, loss=0.0289]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder Epoch 5 Validation Loss: 0.0166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Autoencoder Epoch 6/10: 100%|██████████| 938/938 [00:36<00:00, 26.06batch/s, loss=0.0253]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder Epoch 6 Validation Loss: 0.0163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Autoencoder Epoch 7/10: 100%|██████████| 938/938 [00:36<00:00, 25.98batch/s, loss=0.0271]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder Epoch 7 Validation Loss: 0.0159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Autoencoder Epoch 8/10: 100%|██████████| 938/938 [00:36<00:00, 25.91batch/s, loss=0.0231]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder Epoch 8 Validation Loss: 0.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Autoencoder Epoch 9/10: 100%|██████████| 938/938 [00:37<00:00, 24.84batch/s, loss=0.0248]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder Epoch 9 Validation Loss: 0.0155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Autoencoder Epoch 10/10: 100%|██████████| 938/938 [00:36<00:00, 26.01batch/s, loss=0.0267]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder Epoch 10 Validation Loss: 0.0153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-BQV7z0QdF0",
        "outputId": "2460abbc-9402-40a8-d807-4bdbf89671fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Autoencoder(\n",
              "  (encoder): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.2, inplace=False)\n",
              "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
              "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.2, inplace=False)\n",
              "    (4): Linear(in_features=128, out_features=784, bias=True)\n",
              "    (5): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------\n",
        "# Training LatentCNN (Klassifikation über den latenten Raum des Autoencoders)\n",
        "# ---------------------------------\n",
        "print(\"\\nTraining LatentCNN\")\n",
        "# Wir verwenden wieder CrossEntropyLoss; der Optimizer wird für latentcnn_model definiert.\n",
        "criterion_cls = nn.CrossEntropyLoss()\n",
        "optimizer_lat = optim.Adam(latentcnn_model.parameters(), lr=1e-3)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    latentcnn_model.train()\n",
        "    progress_bar = tqdm(train_loader, desc=f\"LatentCNN Epoch {epoch+1}/{NUM_EPOCHS}\", unit=\"batch\")\n",
        "    for batch in progress_bar:\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        # Hole die latente Darstellung vom Autoencoder\n",
        "        latent_imgs = autoencoder_model.get_latent(imgs)\n",
        "        outputs = latentcnn_model(latent_imgs)\n",
        "        loss = criterion_cls(outputs, labels)\n",
        "\n",
        "        optimizer_lat.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_lat.step()\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    val_loss, val_acc = evaluate_latentcnn(autoencoder_model, latentcnn_model, test_loader, criterion_cls, device)\n",
        "    print(f\"LatentCNN Epoch {epoch+1} Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(\"Early stopping for LatentCNN\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUpJlmbEPE2k",
        "outputId": "8095edaa-53ff-40a5-b26b-f49ee3800f1b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LatentCNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 1/10: 100%|██████████| 938/938 [00:36<00:00, 25.65batch/s, loss=0.375]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 1 Validation Loss: 0.1968, Accuracy: 0.9424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 2/10: 100%|██████████| 938/938 [00:36<00:00, 25.37batch/s, loss=0.413]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 2 Validation Loss: 0.1677, Accuracy: 0.9507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 3/10: 100%|██████████| 938/938 [00:38<00:00, 24.32batch/s, loss=0.118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 3 Validation Loss: 0.1574, Accuracy: 0.9533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 4/10: 100%|██████████| 938/938 [00:35<00:00, 26.32batch/s, loss=0.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 4 Validation Loss: 0.1513, Accuracy: 0.9552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 5/10: 100%|██████████| 938/938 [00:36<00:00, 25.56batch/s, loss=0.332]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 5 Validation Loss: 0.1378, Accuracy: 0.9602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 6/10: 100%|██████████| 938/938 [00:35<00:00, 26.33batch/s, loss=0.0488]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 6 Validation Loss: 0.1334, Accuracy: 0.9610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 7/10: 100%|██████████| 938/938 [00:37<00:00, 24.74batch/s, loss=0.129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 7 Validation Loss: 0.1283, Accuracy: 0.9623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 8/10: 100%|██████████| 938/938 [00:37<00:00, 24.74batch/s, loss=0.342]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 8 Validation Loss: 0.1294, Accuracy: 0.9618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 9/10: 100%|██████████| 938/938 [00:37<00:00, 24.76batch/s, loss=0.192]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 9 Validation Loss: 0.1256, Accuracy: 0.9636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 10/10: 100%|██████████| 938/938 [00:37<00:00, 25.06batch/s, loss=0.211]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 10 Validation Loss: 0.1251, Accuracy: 0.9640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------\n",
        "# Training ResidualCNN (Klassifikation, CrossEntropyLoss)\n",
        "# ---------------------------------\n",
        "print(\"\\nTraining ResidualCNN\")\n",
        "criterion_cls = nn.CrossEntropyLoss()\n",
        "optimizer_res = optim.Adam(residualcnn_model.parameters(), lr=1e-3)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    residualcnn_model.train()\n",
        "    progress_bar = tqdm(train_loader, desc=f\"ResidualCNN Epoch {epoch+1}/{NUM_EPOCHS}\", unit=\"batch\")\n",
        "    for batch in progress_bar:\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        outputs = residualcnn_model(imgs)\n",
        "        loss = criterion_cls(outputs, labels)\n",
        "\n",
        "        optimizer_res.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_res.step()\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    val_loss, val_acc = evaluate_classifier(residualcnn_model, test_loader, criterion_cls, device)\n",
        "    print(f\"ResidualCNN Epoch {epoch+1} Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(\"Early stopping for ResidualCNN\")\n",
        "            break"
      ],
      "metadata": {
        "id": "gacIP-avO1sT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4faf0f0-c9a0-4a48-d76f-f60a7448d518"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training ResidualCNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 1/10: 100%|██████████| 938/938 [00:43<00:00, 21.47batch/s, loss=0.019]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 1 Validation Loss: 0.0400, Accuracy: 0.9880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 2/10: 100%|██████████| 938/938 [00:42<00:00, 22.26batch/s, loss=0.0994]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 2 Validation Loss: 0.0357, Accuracy: 0.9883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 3/10: 100%|██████████| 938/938 [00:42<00:00, 21.89batch/s, loss=0.0191]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 3 Validation Loss: 0.0265, Accuracy: 0.9915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 4/10: 100%|██████████| 938/938 [00:42<00:00, 21.91batch/s, loss=0.274]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 4 Validation Loss: 0.0244, Accuracy: 0.9927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 5/10: 100%|██████████| 938/938 [00:41<00:00, 22.46batch/s, loss=0.207]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 5 Validation Loss: 0.0279, Accuracy: 0.9915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 6/10: 100%|██████████| 938/938 [00:41<00:00, 22.82batch/s, loss=0.245]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 6 Validation Loss: 0.0208, Accuracy: 0.9933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 7/10: 100%|██████████| 938/938 [00:41<00:00, 22.41batch/s, loss=0.00429]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 7 Validation Loss: 0.0232, Accuracy: 0.9935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 8/10: 100%|██████████| 938/938 [00:42<00:00, 22.03batch/s, loss=0.00395]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 8 Validation Loss: 0.0205, Accuracy: 0.9938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 9/10: 100%|██████████| 938/938 [00:40<00:00, 22.88batch/s, loss=0.0229]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 9 Validation Loss: 0.0222, Accuracy: 0.9934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 10/10: 100%|██████████| 938/938 [00:40<00:00, 22.88batch/s, loss=0.00708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 10 Validation Loss: 0.0177, Accuracy: 0.9948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latentcnn_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        x = autoencoder_model.get_latent(imgs)\n",
        "        outputs = latentcnn_model(x)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Berechnung der Metriken mit scikit-learn\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='macro')\n",
        "recall = recall_score(all_labels, all_preds, average='macro')\n",
        "f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Precision: {precision:.4f}\")\n",
        "print(f\"Test Recall: {recall:.4f}\")\n",
        "print(f\"Test F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "jKa_-z4pPZV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01c19cb-0b03-45f2-845c-8287bc9b1c2c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:05<00:00, 29.07batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9640\n",
            "Test Precision: 0.9638\n",
            "Test Recall: 0.9636\n",
            "Test F1 Score: 0.9637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "residualcnn_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        outputs = residualcnn_model(imgs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Berechnung der Metriken mit scikit-learn\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='macro')\n",
        "recall = recall_score(all_labels, all_preds, average='macro')\n",
        "f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Precision: {precision:.4f}\")\n",
        "print(f\"Test Recall: {recall:.4f}\")\n",
        "print(f\"Test F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "THWsYibTPiZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d2319e-2436-4120-d0e8-6ea401a548d7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:05<00:00, 31.36batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9948\n",
            "Test Precision: 0.9949\n",
            "Test Recall: 0.9947\n",
            "Test F1 Score: 0.9948\n"
          ]
        }
      ]
    }
  ]
}
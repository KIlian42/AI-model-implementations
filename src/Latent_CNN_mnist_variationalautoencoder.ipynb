{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNTQ-Zxpa-HB",
        "outputId": "066ec016-f5cf-4ce9-acc8-ae34e792a613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Feb 12 11:05:06 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPgPw0rnRuM4",
        "outputId": "4c48e3d5-31a8-4c9a-b8f3-762d15fed965"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "NUM_EPOCHS = 50\n",
        "PATIENCE = 3"
      ],
      "metadata": {
        "id": "rIcQ_RqlzwDP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiMe3Tt4TVjf",
        "outputId": "e495d0bc-e7da-42b4-86f9-764e4b5a3259"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist_dataset():\n",
        "    mnist_dataset = load_dataset(\"mnist\")\n",
        "    transform = transforms.ToTensor()\n",
        "\n",
        "    def _transform_example(example):\n",
        "        example[\"image\"] = transform(example[\"image\"])\n",
        "        return example\n",
        "\n",
        "    mnist_dataset = mnist_dataset.map(_transform_example)\n",
        "    mnist_dataset.set_format(type=\"torch\", columns=[\"image\", \"label\"])\n",
        "\n",
        "    train_dataset = mnist_dataset[\"train\"]\n",
        "    test_dataset = mnist_dataset[\"test\"]\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "Vi4Ds0zBbleq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim=64):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        self.encoder_fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.encoder_bn1 = nn.BatchNorm1d(128)\n",
        "        self.encoder_fc2 = nn.Linear(128, 64)\n",
        "        self.encoder_bn2 = nn.BatchNorm1d(64)\n",
        "\n",
        "        self.fc_mean = nn.Linear(64, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(64, latent_dim)\n",
        "\n",
        "        self.decoder_fc1 = nn.Linear(latent_dim, 64)\n",
        "        self.decoder_bn1 = nn.BatchNorm1d(64)\n",
        "        self.decoder_fc2 = nn.Linear(64, 128)\n",
        "        self.decoder_bn2 = nn.BatchNorm1d(128)\n",
        "        self.decoder_fc3 = nn.Linear(128, 28 * 28)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = x.view(x.size(0), -1) # [Batch, 1, 28, 28] → [Batch, 784]\n",
        "        h = self.encoder_fc1(x)\n",
        "        h = self.encoder_bn1(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.encoder_fc2(h)\n",
        "        h = self.encoder_bn2(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        mu = self.fc_mean(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std) # Sample\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = self.decoder_fc1(z)\n",
        "        h = self.decoder_bn1(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.decoder_fc2(h)\n",
        "        h = self.decoder_bn2(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        out = self.decoder_fc3(h)\n",
        "        out = torch.sigmoid(out)  # Normalize → [0, 1]\n",
        "        out = out.view(-1, 1, 28, 28)\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        decoded = self.decode(z)\n",
        "        return decoded, mu, logvar\n",
        "\n",
        "    def get_latent(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return z"
      ],
      "metadata": {
        "id": "JnqmzwDftllb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1, dropout_prob: float = 0.2):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.downsample = None\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = ResidualBlock(16, 16, stride=1, dropout_prob=0.2)\n",
        "        self.layer2 = ResidualBlock(16, 32, stride=2, dropout_prob=0.2)\n",
        "        self.layer3 = ResidualBlock(32, 64, stride=2, dropout_prob=0.2)\n",
        "        self.layer4 = ResidualBlock(64, 64, stride=1, dropout_prob=0.2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout_fc = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout_fc(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "LTNlrTMofjBr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LatentCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LatentCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(p=0.5)  # Dropout-Wahrscheinlichkeit von 50%\n",
        "        self.fc = nn.Linear(32 * 8 * 8, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1, 8, 8)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jWLOsb2O0U6P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Evaluation functions\n",
        "# ---------------------------\n",
        "def evaluate_varationalautoencoder(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            imgs = batch[\"image\"].to(device)\n",
        "            # Bei einem VAE liefert der Forward-Pass (rekonstruierte Bilder, mu, logvar)\n",
        "            recon_x, mu, logvar = model(imgs)\n",
        "            loss = vae_loss(recon_x, imgs, mu, logvar)\n",
        "            # Da wir \"sum\" als Reduction verwenden, summieren wir bereits über die Batch-Größe\n",
        "            total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(data_loader.dataset)\n",
        "    return avg_loss\n",
        "\n",
        "def evaluate_residualcnn(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            imgs = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    avg_loss = total_loss / len(data_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def evaluate_latentcnn(variational_autoencoder, latentcnn, data_loader, criterion, device):\n",
        "    variational_autoencoder.eval()\n",
        "    latentcnn.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            imgs = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            latent_imgs = variational_autoencoder.get_latent(imgs)\n",
        "            outputs = latentcnn(latent_imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    avg_loss = total_loss / len(data_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "s0vezAdbWfhw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = load_mnist_dataset()\n",
        "\n",
        "variational_autoencoder_model = VariationalAutoencoder().to(device)\n",
        "latentcnn_model = LatentCNN().to(device)\n",
        "residualcnn_model = ResidualCNN().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN0yQRxiOu0d",
        "outputId": "b6961cc8-23d3-4946-fe5e-674922db1d0e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------\n",
        "# Training Variational Autoencoder\n",
        "# ---------------------------------\n",
        "print(\"Training VAE\")\n",
        "optimizer_vae = optim.Adam(variational_autoencoder_model.parameters(), lr=1e-3)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "# Lossfunktion für den VAE: Rekonstruktionsverlust + KL-Divergenz\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    # Binary Cross-Entropy (BCE) als Rekonstruktionsverlust\n",
        "    # Wir flachen beide Tensoren zu [Batch, 784] ab.\n",
        "    BCE = F.binary_cross_entropy(recon_x.view(-1, 28*28), x.view(-1, 28*28), reduction='sum')\n",
        "    # KL-Divergenz: Vergleicht die latente Verteilung mit einer Standardnormalverteilung\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    variational_autoencoder_model.train()\n",
        "    progress_bar = tqdm(train_loader, desc=f\"VAE Epoch {epoch+1}/{NUM_EPOCHS}\", unit=\"batch\")\n",
        "    for batch in progress_bar:\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        recon_x, mu, logvar = variational_autoencoder_model(imgs)\n",
        "        loss = vae_loss(recon_x, imgs, mu, logvar)\n",
        "\n",
        "        optimizer_vae.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_vae.step()\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    val_loss = evaluate_varationalautoencoder(variational_autoencoder_model, test_loader, device)\n",
        "    print(f\"VAE Epoch {epoch+1} Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Early Stopping Logik\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_no_improve = 0\n",
        "        # Hier könntest du das Modell abspeichern, z.B.\n",
        "        # torch.save(variational_autoencoder_model.state_dict(), \"best_vae_model.pth\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(\"Early stopping for VAE\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK6SRhZjs2gC",
        "outputId": "5ae0c05e-d70f-4ac8-9d08-47d4b35fbb6b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training VAE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 1/50: 100%|██████████| 938/938 [00:43<00:00, 21.56batch/s, loss=5.7e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 1 Validation Loss: 155.8810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 2/50: 100%|██████████| 938/938 [00:37<00:00, 24.97batch/s, loss=4.69e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 2 Validation Loss: 142.0184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 3/50: 100%|██████████| 938/938 [00:35<00:00, 26.18batch/s, loss=5.39e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 3 Validation Loss: 136.6266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 4/50: 100%|██████████| 938/938 [00:35<00:00, 26.24batch/s, loss=5.33e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 4 Validation Loss: 134.7481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 5/50: 100%|██████████| 938/938 [00:35<00:00, 26.27batch/s, loss=5.22e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 5 Validation Loss: 133.6583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 6/50: 100%|██████████| 938/938 [00:36<00:00, 25.64batch/s, loss=4.63e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 6 Validation Loss: 132.6207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 7/50: 100%|██████████| 938/938 [00:35<00:00, 26.27batch/s, loss=4.42e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 7 Validation Loss: 132.3621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 8/50: 100%|██████████| 938/938 [00:35<00:00, 26.56batch/s, loss=4.79e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 8 Validation Loss: 131.4551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 9/50: 100%|██████████| 938/938 [00:35<00:00, 26.30batch/s, loss=5.19e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 9 Validation Loss: 131.3699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 10/50: 100%|██████████| 938/938 [00:35<00:00, 26.21batch/s, loss=4.85e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 10 Validation Loss: 130.9597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 11/50: 100%|██████████| 938/938 [00:35<00:00, 26.11batch/s, loss=4.59e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 11 Validation Loss: 130.8153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 12/50: 100%|██████████| 938/938 [00:35<00:00, 26.22batch/s, loss=4.32e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 12 Validation Loss: 130.6281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 13/50: 100%|██████████| 938/938 [00:35<00:00, 26.31batch/s, loss=4.47e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 13 Validation Loss: 130.2488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 14/50: 100%|██████████| 938/938 [00:35<00:00, 26.31batch/s, loss=4.22e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 14 Validation Loss: 130.4939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 15/50: 100%|██████████| 938/938 [00:35<00:00, 26.44batch/s, loss=4.57e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 15 Validation Loss: 129.7557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 16/50: 100%|██████████| 938/938 [00:35<00:00, 26.26batch/s, loss=4.43e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 16 Validation Loss: 129.9756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 17/50: 100%|██████████| 938/938 [00:35<00:00, 26.25batch/s, loss=5.14e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 17 Validation Loss: 129.3899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 18/50: 100%|██████████| 938/938 [00:35<00:00, 26.40batch/s, loss=4.57e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 18 Validation Loss: 129.4404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 19/50: 100%|██████████| 938/938 [00:39<00:00, 23.55batch/s, loss=4.74e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 19 Validation Loss: 129.2269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 20/50: 100%|██████████| 938/938 [00:35<00:00, 26.20batch/s, loss=4.74e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 20 Validation Loss: 129.0542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 21/50: 100%|██████████| 938/938 [00:35<00:00, 26.23batch/s, loss=4.35e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 21 Validation Loss: 128.9712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 22/50: 100%|██████████| 938/938 [00:35<00:00, 26.24batch/s, loss=4.58e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 22 Validation Loss: 128.8275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 23/50: 100%|██████████| 938/938 [00:35<00:00, 26.31batch/s, loss=4.9e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 23 Validation Loss: 129.0683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 24/50: 100%|██████████| 938/938 [00:35<00:00, 26.22batch/s, loss=4.79e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 24 Validation Loss: 129.3439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 25/50: 100%|██████████| 938/938 [00:36<00:00, 26.01batch/s, loss=4.59e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 25 Validation Loss: 128.3967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 26/50: 100%|██████████| 938/938 [00:35<00:00, 26.20batch/s, loss=4.54e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 26 Validation Loss: 128.7914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 27/50: 100%|██████████| 938/938 [00:35<00:00, 26.15batch/s, loss=4.49e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 27 Validation Loss: 128.4400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAE Epoch 28/50: 100%|██████████| 938/938 [00:35<00:00, 26.10batch/s, loss=4.72e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE Epoch 28 Validation Loss: 128.5298\n",
            "Early stopping for VAE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------\n",
        "# Training LatentCNN (Klassifikation über den latenten Raum des Autoencoders)\n",
        "# ---------------------------------\n",
        "print(\"\\nTraining LatentCNN\")\n",
        "criterion_cls = nn.CrossEntropyLoss()\n",
        "optimizer_lat = optim.Adam(latentcnn_model.parameters(), lr=1e-3)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    latentcnn_model.train()\n",
        "    progress_bar = tqdm(train_loader, desc=f\"LatentCNN Epoch {epoch+1}/{NUM_EPOCHS}\", unit=\"batch\")\n",
        "    for batch in progress_bar:\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        # Hole die latente Darstellung vom Autoencoder\n",
        "        latent_imgs = variational_autoencoder_model.get_latent(imgs)\n",
        "        outputs = latentcnn_model(latent_imgs)\n",
        "        loss = criterion_cls(outputs, labels)\n",
        "\n",
        "        optimizer_lat.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_lat.step()\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    val_loss, val_acc = evaluate_latentcnn(variational_autoencoder_model, latentcnn_model, test_loader, criterion_cls, device)\n",
        "    print(f\"LatentCNN Epoch {epoch+1} Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(\"Early stopping for LatentCNN\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUpJlmbEPE2k",
        "outputId": "094c04be-4150-4ab9-bb41-afe24c358472"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LatentCNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 1/50: 100%|██████████| 938/938 [00:35<00:00, 26.54batch/s, loss=1.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 1 Validation Loss: 0.6967, Accuracy: 0.7603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 2/50: 100%|██████████| 938/938 [00:35<00:00, 26.71batch/s, loss=0.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 2 Validation Loss: 0.6369, Accuracy: 0.7976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 3/50: 100%|██████████| 938/938 [00:35<00:00, 26.56batch/s, loss=0.84]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 3 Validation Loss: 0.6149, Accuracy: 0.7996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 4/50: 100%|██████████| 938/938 [00:34<00:00, 26.85batch/s, loss=0.94]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 4 Validation Loss: 0.5987, Accuracy: 0.8062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 5/50: 100%|██████████| 938/938 [00:34<00:00, 26.81batch/s, loss=0.855]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 5 Validation Loss: 0.5975, Accuracy: 0.8065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 6/50: 100%|██████████| 938/938 [00:35<00:00, 26.52batch/s, loss=0.718]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 6 Validation Loss: 0.5864, Accuracy: 0.8106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 7/50: 100%|██████████| 938/938 [00:35<00:00, 26.64batch/s, loss=0.875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 7 Validation Loss: 0.5815, Accuracy: 0.8109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 8/50: 100%|██████████| 938/938 [00:35<00:00, 26.65batch/s, loss=0.816]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 8 Validation Loss: 0.5707, Accuracy: 0.8147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 9/50: 100%|██████████| 938/938 [00:34<00:00, 26.83batch/s, loss=0.98]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 9 Validation Loss: 0.5579, Accuracy: 0.8186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 10/50: 100%|██████████| 938/938 [00:36<00:00, 26.03batch/s, loss=1.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 10 Validation Loss: 0.5633, Accuracy: 0.8178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 11/50: 100%|██████████| 938/938 [00:35<00:00, 26.63batch/s, loss=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 11 Validation Loss: 0.5618, Accuracy: 0.8187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LatentCNN Epoch 12/50: 100%|██████████| 938/938 [00:35<00:00, 26.68batch/s, loss=0.799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentCNN Epoch 12 Validation Loss: 0.5600, Accuracy: 0.8235\n",
            "Early stopping for LatentCNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------\n",
        "# Training ResidualCNN (Klassifikation, CrossEntropyLoss)\n",
        "# ---------------------------------\n",
        "print(\"\\nTraining ResidualCNN\")\n",
        "criterion_cls = nn.CrossEntropyLoss()\n",
        "optimizer_res = optim.Adam(residualcnn_model.parameters(), lr=1e-3)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    residualcnn_model.train()\n",
        "    progress_bar = tqdm(train_loader, desc=f\"ResidualCNN Epoch {epoch+1}/{NUM_EPOCHS}\", unit=\"batch\")\n",
        "    for batch in progress_bar:\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        outputs = residualcnn_model(imgs)\n",
        "        loss = criterion_cls(outputs, labels)\n",
        "\n",
        "        optimizer_res.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_res.step()\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    val_loss, val_acc = evaluate_residualcnn(residualcnn_model, test_loader, criterion_cls, device)\n",
        "    print(f\"ResidualCNN Epoch {epoch+1} Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(\"Early stopping for ResidualCNN\")\n",
        "            break"
      ],
      "metadata": {
        "id": "gacIP-avO1sT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5456f5-e5e7-4e68-ef7e-0d8d8acea8ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training ResidualCNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 1/50: 100%|██████████| 938/938 [00:40<00:00, 23.43batch/s, loss=0.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 1 Validation Loss: 0.0713, Accuracy: 0.9782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 2/50: 100%|██████████| 938/938 [00:40<00:00, 22.99batch/s, loss=0.0422]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 2 Validation Loss: 0.0297, Accuracy: 0.9904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 3/50: 100%|██████████| 938/938 [00:39<00:00, 23.45batch/s, loss=0.266]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 3 Validation Loss: 0.0268, Accuracy: 0.9913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 4/50: 100%|██████████| 938/938 [00:40<00:00, 23.04batch/s, loss=0.0785]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 4 Validation Loss: 0.0225, Accuracy: 0.9929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 5/50: 100%|██████████| 938/938 [00:40<00:00, 23.07batch/s, loss=0.114]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 5 Validation Loss: 0.0217, Accuracy: 0.9930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 6/50: 100%|██████████| 938/938 [00:40<00:00, 23.42batch/s, loss=0.0107]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 6 Validation Loss: 0.0171, Accuracy: 0.9954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 7/50: 100%|██████████| 938/938 [00:39<00:00, 23.49batch/s, loss=0.0658]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 7 Validation Loss: 0.0193, Accuracy: 0.9940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 8/50: 100%|██████████| 938/938 [00:40<00:00, 23.03batch/s, loss=0.307]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 8 Validation Loss: 0.0200, Accuracy: 0.9939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ResidualCNN Epoch 9/50: 100%|██████████| 938/938 [00:40<00:00, 22.99batch/s, loss=0.0118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualCNN Epoch 9 Validation Loss: 0.0223, Accuracy: 0.9940\n",
            "Early stopping for ResidualCNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------\n",
        "# Evaluate LatentCNN\n",
        "# ---------------------------------\n",
        "\n",
        "latentcnn_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        x = variational_autoencoder_model.get_latent(imgs)\n",
        "        outputs = latentcnn_model(x)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Berechnung der Metriken mit scikit-learn\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='macro')\n",
        "recall = recall_score(all_labels, all_preds, average='macro')\n",
        "f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Precision: {precision:.4f}\")\n",
        "print(f\"Test Recall: {recall:.4f}\")\n",
        "print(f\"Test F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "jKa_-z4pPZV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2742d96f-46c2-409a-a00d-fc3186135b21"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:04<00:00, 34.79batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8152\n",
            "Test Precision: 0.8144\n",
            "Test Recall: 0.8117\n",
            "Test F1 Score: 0.8099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------\n",
        "# Residual LatentCNN\n",
        "# ---------------------------------\n",
        "\n",
        "residualcnn_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        outputs = residualcnn_model(imgs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Berechnung der Metriken mit scikit-learn\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='macro')\n",
        "recall = recall_score(all_labels, all_preds, average='macro')\n",
        "f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Precision: {precision:.4f}\")\n",
        "print(f\"Test Recall: {recall:.4f}\")\n",
        "print(f\"Test F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "THWsYibTPiZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e1df0b-826f-421a-a7e1-b305251e2d8c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:05<00:00, 28.62batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9940\n",
            "Test Precision: 0.9940\n",
            "Test Recall: 0.9940\n",
            "Test F1 Score: 0.9940\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K-wIuPEkYeL",
        "outputId": "7520332f-0eda-40ff-86a8-97d90e9433cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision tqdm matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "emIehKr4ko7E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformationen für die Bilder\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),  # Größe anpassen\n",
        "    transforms.Grayscale(num_output_channels=3),  # Konvertiere in 3 Kanäle\n",
        "    transforms.ToTensor(),  # In Tensor umwandeln\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalisierung auf [-1, 1]\n",
        "])\n",
        "\n",
        "# Dataset laden (hier MNIST)\n",
        "dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "\n",
        "# Dataloader definieren\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8cAaLM9kuum",
        "outputId": "a43ebcf3-4c14-46ee-99c8-a7efe3d5859f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 14.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 509kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.53MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.67MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=6, out_channels=3, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, hidden_dim, 3, padding=1),  # Eingabekanäle auf 6 ändern\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.middle = nn.Sequential(\n",
        "            nn.Conv2d(hidden_dim, hidden_dim * 2, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_dim * 2, hidden_dim, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_dim, out_channels, 3, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        # Zeitinformation als zusätzlichen Kanal hinzufügen\n",
        "        time_embedding = t.view(-1, 1, 1, 1).expand_as(x)\n",
        "        x = torch.cat([x, time_embedding], dim=1)  # Füge Zeitkanal zu den Bildkanälen hinzu\n",
        "        x = self.encoder(x)\n",
        "        x = self.middle(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qGdBXyFck7PB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(x, t, noise=None):\n",
        "    \"\"\"\n",
        "    Fügt einem Bild Rauschen basierend auf Zeit t hinzu.\n",
        "    x: Bildtensor [Batch, Channels, Height, Width]\n",
        "    t: Zeitindex [Batch]\n",
        "    noise: Optional, falls nicht gegeben, wird normalverteiltes Rauschen erzeugt.\n",
        "    \"\"\"\n",
        "    if noise is None:\n",
        "        noise = torch.randn_like(x)\n",
        "    alphas = torch.linspace(0.0001, 0.02, t.max() + 1).to(x.device)\n",
        "    alpha_t = alphas[t].view(-1, 1, 1, 1)  # Formate alpha für Multiplikation\n",
        "    noisy_x = torch.sqrt(alpha_t) * x + torch.sqrt(1 - alpha_t) * noise\n",
        "    return noisy_x, noise\n",
        "\n",
        "def diffusion_loss(model, x, t):\n",
        "    noisy_x, true_noise = add_noise(x, t)\n",
        "    predicted_noise = model(noisy_x, t)\n",
        "    loss = F.mse_loss(predicted_noise, true_noise)  # MSE zwischen echtem und vorhergesagtem Rauschen\n",
        "    return loss\n",
        "\n",
        "def sample(model, img_shape, steps=100):\n",
        "    x = torch.randn(img_shape).to(device)  # Start mit reinem Rauschen\n",
        "    for t in reversed(range(steps)):\n",
        "        t_tensor = torch.tensor([t] * img_shape[0], device=device)\n",
        "        predicted_noise = model(x, t_tensor)\n",
        "        alphas = torch.linspace(0.0001, 0.02, steps).to(x.device)\n",
        "        alpha_t = alphas[t]\n",
        "        x = (x - torch.sqrt(1 - alpha_t) * predicted_noise) / torch.sqrt(alpha_t)\n",
        "    return x"
      ],
      "metadata": {
        "id": "I3XyaND6k11k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Beispiel-Trainingsloop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):  # Dummy-Epochen\n",
        "    epoch_loss = 0  # Loss für die aktuelle Epoche\n",
        "    with tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\") as pbar:  # Fortschrittsbalken pro Epoche\n",
        "        for images, _ in pbar:  # DataLoader liefert (Bilder, Labels)\n",
        "            images = images.to(device)\n",
        "            t = torch.randint(0, 100, (images.size(0),), device=device)  # Zeitindizes\n",
        "            loss = diffusion_loss(model, images, t)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            pbar.set_postfix(loss=loss.item())  # Fortschrittsbalken mit aktuellem Loss anzeigen\n",
        "\n",
        "    # Nach jeder Epoche den durchschnittlichen Loss ausgeben\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {epoch_loss / len(dataloader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlR78o6slIjd",
        "outputId": "2ab20f38-0d59-4a01-b4ea-f749d50380ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  36%|███▌      | 679/1875 [00:46<01:22, 14.46it/s, loss=0.0474]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Beispiel: Erzeugung eines Bildes\n",
        "generated_images = sample(model, (8, 3, 64, 64))  # Batch von 8 Bildern mit 3 Kanälen, 64x64 Pixel\n",
        "plt.imshow(generated_images[0].permute(1, 2, 0).cpu().detach().numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tlLPSoaYlJZV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}